<!DOCTYPE html>
<!-- saved from url=(0029)https://carrac.co.jp/service/ -->
<html lang="ja"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Jesse Yule's Blog</title>
    <meta name="viewport" content="width=device-width">

    <style>.l-page { visibility: hidden; }</style>
    <link rel="stylesheet" as="style" href="../../css/main/main.min.css">
    <link rel="apple-touch-icon" sizes="180x180" href="https://carrac.co.jp/img/common/app_icon.png">

    <link rel="stylesheet" href="../../css/menu/common.css" media="all">
    <link rel="stylesheet" href="../../css/menu/home.css" media="all">
    <script type="text/javascript" async="" src="../../css/menu/analytics.js"></script>
    <script async="" src="../../css/menu/js"></script>


    <meta name="theme-color" content="#ffffff">

    <script type="text/javascript" async="" src="../../css/main/analytics.js"></script><script async="" src="../../css/main/gtm.js"></script><script>
      (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
      new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
      j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
      })(window,document,'script','dataLayer','GTM-KHDRBVP');
    </script>
    <!-- End Google Tag Manager -->
  </head>
  <body style="font-family: 等线, 等线 Light,'微软雅黑 Light',Helvetica Neue, Helvetica, Arial, PingFang SC; font-weight: lighter;word-break: break-all ;background-color: #323638  ">
    <!-- Google Tag Manager (noscript) -->
    <noscript>
      &lt;iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KHDRBVP"
      height="0" width="0" style="display:none;visibility:hidden"&gt;
      &lt;/iframe&gt;
    </noscript>
    <!-- End Google Tag Manager (noscript) -->
    
    <div class="l-page" data-page-id="service">
      <!-- Start to define the global header.-->
      <div class="l-gh"></div>
      <!-- End to define the global header.-->




      <div class="l-contents">
        <!-- Start to define the main content.-->

          <header class="st-hdr" id="js-hdr">
              <div class="hdr-bar m-row m-row--jc--spacebetween m-row--ai--center">

              </div>

          </header>

          <button class="trigger" id="js-trigger"><span></span><span></span><span></span></button>


          <nav class="overlay-navigation" style="color: #eeeeee">
              <div class="overlay-navigation__inner m-row">
                  <div class="overlay-navigation__block">
                      <ul class="sitemap m-row m-row--fw--wrap">

                          <li class="sitemap__unit"><a href="../../index.html">Home</a></li>

                          <li class="sitemap__unit"><a href="../../about/about.html">About</a></li>

                          <li class="sitemap__unit"><a href="../../programming/topic.html">Programming</a></li>

                          <li class="sitemap__unit"><a href="../topic.html">Mathematics</a></li>

                          <li class="sitemap__unit"><a href="../../datascience/datascience.html">Data Science</a></li>

                          <li class="sitemap__unit"><a href="../../machinelearning/topic.html">Machine Learning</a></li>

                          <li class="sitemap__unit"><a href="../../projects/topic.html">Projects</a></li>

                          <li class="sitemap__unit"><a href="../../articles/articles.html">Others</a></li>

                      </ul>

                  </div>
                  <div class="sns"><h2 class="overlay-navigation__siteID"><img src="../../css/menu/img_siteID-m.svg"
                                                                               alt=""></h2></div>
              </div>
          </nav>



          <div class="p-lower">
          <div class="c-red-line c-slide-in u-animdel-100"></div>
          <h2 class="p-lower__title-en c-slide-in u-animdel-100">概率统计概述（二）</h2>
		  

		  
		   <div class="p-lower-kv">
            <div class="p-lower-kv__text">

                <div class="p-lower-kv__outline p-lower-kv__outline--col2">之前已经提及到条件分布和边缘分布，接下来将介绍一些离散型的经典分布的例子。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
			  <div class="p-lower-kv__outline p-lower-kv__outline--col2">首先要介绍的是均匀分布，这是最简单的分布了，其实没什么好说的。主要注意，均匀分布仅仅有离散型还有连续型，而连续型和离散型的期望与方差有一点点细微区别。</div>
              <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
              <div class="p-lower-kv__outline p-lower-kv__outline--col2">接下来我们开始介绍几个典型的离散分布，首先是二项分布（Binomial distribution），如果进行n次试验，每次试验完全相同且只有两种可能，这种分布状况就是二项分布。其中，如果只进行一次实验，则成为伯努利试验，服从伯努利分布，是、换句话说，二项分布可以看成n重伯努利试验服从的分布。</div>
            <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
            <div class="p-lower-kv__outline p-lower-kv__outline--col2">然后是超几何分布（Hypergeometric distribution），它和二项分布比较接近，主要区别是二项分布每次实验之间是没有影响的，超几何分布每次实验之间是有影响的，一个很经典的例子，红球白球，每次抽了放回去就是服从二项分布，抽了不放回去就是超几何分布。一般来说，超几何分布的问题都是类似于N件产品有M件不及格，抽n件有k件不及格的概率有多少。</div>

                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>

                <div class="p-lower-kv__outline p-lower-kv__outline--col2">除了二项分布和超几何分布，还有一种就是几何分布，可以这样说去理解三者的区别，二项分布和超集合分布都是研究做n次实验成功k次的概率分布（一个是试验间相互独立一个是相互影响），而几何分布则是研究做n次试验成功第一次的概率分布。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">既然有几何分布研究做n次实验成功第一次的概率分布，当然也会有做n次实验成功第k次的概率分布，也就是负二项分布。关于它为什么叫负二项分布，我认为主要原因是如果排除了第n次实验，它的前n次实验就是服从二项分布的。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">另一方面，因为二项分布每次实验只有两种结果，如果结果的数量增多，那么服从的分布就是multinomial distribution。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">离散型分布还有一种就是泊松分布，主要指一段时间内事件发生x次的概率。从概率公式的推导来看，泊松分布和二项分布的关系也是非常接近。首先，针对泊松分布，假如我们把实验的时间划分成一个个小区间，如果划分得足够小，那么每个区间只会有事件发生一次和不发生两种情况，这时候，泊松分布和二项分布就很接近了。为了从二项分布推导出泊松分布的公式，我们往往会做等量代换p=lamda/n(其中lamda是常数，实际上他就是泊松分布的期望值,指单位时间发生事件的平均次数)，然后让n趋于无穷，进而推导出泊松分布的公式。但是泊松分布和二项分布有什么不同？虽然他们都是指实验成功n次的概率分布，但是对于二项分布我们是知道实验的总次数的，泊松分布却不知道（它只是说一段时间内事件发生n次，不像二项分布说做N次实验发生n次的概率）。用一个例子去解释的话，就像二项分布会研究十字路口交通事故发生次数与经过的车辆之间的关系，而泊松分布则主要研究十字路口事故发生的次数。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">总的来说，对于离散型的概率分布，二项分布是最基础的，它研究做N次实验成功n次的概率分布。伯努利实验是它的特例，研究只做一次实验成功的概率是多少。如果我们研究做N次实验第一次成功的概率的分布，那就是几何分布。如果研究做N次实验第n次成功的概率，那就是负二项分布。在这里提到的实验，不同实验之间是相互独立的，如果是实验间相互影响的二项分布就是超几何分布。最后还有一种由二项分布推导出来的泊松分布，它和前面提到的所有实验都不同，因为它并不知道实验的总次数，而是关注一定时间内实验成功n次的概率分布。</div>







                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">参考资料：<br>
                (1)https://zhuanlan.zhihu.com/p/26433704<br>
                    (2)http://hongyitong.github.io/2016/11/13/%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83%E3%80%81%E6%B3%8A%E6%9D%BE%E5%88%86%E5%B8%83%E3%80%81%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83/<br>

                </div>


        </div>

        <!-- End to define the main content.-->
      </div>


    </div>
    <script src="../../css/main/main.min.js" async=""></script>

    <script type="text/javascript" defer=""
            src="../../css/menu/autoptimize_73b1aaeb49de3f7372d04614ffa9ecd3.js"></script>

</body></html>