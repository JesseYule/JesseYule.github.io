<!DOCTYPE html>
<!-- saved from url=(0029)https://carrac.co.jp/service/ -->
<html lang="ja"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Jesse Yule's Blog</title>
    <meta name="viewport" content="width=device-width">

    <style>.l-page { visibility: hidden; }</style>
    <link rel="stylesheet" as="style" href="../../css/main/main.min.css">
    <link rel="apple-touch-icon" sizes="180x180" href="https://carrac.co.jp/img/common/app_icon.png">

    <link rel="stylesheet" href="../../css/menu/common.css" media="all">
    <link rel="stylesheet" href="../../css/menu/home.css" media="all">
    <script type="text/javascript" async="" src="../../css/menu/analytics.js"></script>
    <script async="" src="../../css/menu/js"></script>


    <meta name="theme-color" content="#ffffff">
    <!-------------------------matjax------------------------------>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
    <!---------------------------------------------------------------->
    <script type="text/javascript" async="" src="../../css/main/analytics.js"></script><script async="" src="../../css/main/gtm.js"></script><script>
      (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
      new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
      j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
      })(window,document,'script','dataLayer','GTM-KHDRBVP');
    </script>
    <!-- End Google Tag Manager -->
  </head>
  <body style="font-family: 等线, 等线 Light,'微软雅黑 Light',Helvetica Neue, Helvetica, Arial, PingFang SC; font-weight: lighter ;word-break: break-all ;background-color: #323638 ">
    <!-- Google Tag Manager (noscript) -->
    <noscript>
      &lt;iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KHDRBVP"
      height="0" width="0" style="display:none;visibility:hidden"&gt;
      &lt;/iframe&gt;
    </noscript>
    <!-- End Google Tag Manager (noscript) -->
    
    <div class="l-page" data-page-id="service">
      <!-- Start to define the global header.-->
      <div class="l-gh"></div>
      <!-- End to define the global header.-->




      <div class="l-contents">
        <!-- Start to define the main content.-->

          <header class="st-hdr" id="js-hdr">
              <div class="hdr-bar m-row m-row--jc--spacebetween m-row--ai--center">

              </div>

          </header>

          <button class="trigger" id="js-trigger"><span></span><span></span><span></span></button>



          <nav class="overlay-navigation" style="color: #eeeeee">
              <div class="overlay-navigation__inner m-row">
                  <div class="overlay-navigation__block">
                      <ul class="sitemap m-row m-row--fw--wrap">

                              <li class="sitemap__unit"><a href="../../index.html">Home</a></li>

                          <li class="sitemap__unit"><a href="../../about/about.html">About</a></li>

                          <li class="sitemap__unit"><a href="../../programming/java1.html">Java</a></li>



                          <li class="sitemap__unit"><a href="../../math/all1.html">Mathematics</a></li>

                          <li class="sitemap__unit"><a href="../../naturallanguage/all1.html">Natural Language</a></li>

                          <li class="sitemap__unit"><a href="../../machinelearning/ml1.html">Machine Learning</a></li>

<li class="sitemap__unit"><a href="../../articles/all1.html">Others</a></li>

                      </ul>

                  </div>
                  <div class="sns"><h2 class="overlay-navigation__siteID"><img src="../../css/menu/img_siteID-m.svg"
                                                                               alt=""></h2></div>
              </div>
          </nav>



          <div class="p-lower">
          <div class="c-red-line c-slide-in u-animdel-100"></div>
          <h2 class="p-lower__title-en c-slide-in u-animdel-100">DST与Neural Belief Tracker</h2>

		  
		   <div class="p-lower-kv">
            <div class="p-lower-kv__text">
              <div class="p-lower-kv__subtitle">  </div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">之前介绍了自然语言理解、对话管理，其中对话管理包括DST和DPL，简单再说一遍，NLU是为了分析单一输入的语义，通过intent和slot表示语义，而DST是为了结合当前输入、上一时刻的输入和上一时刻系统的action分析出综合语义state，一般也是用intent和slot表示，而DPL则是基于得到的state分析action。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">这里主要结合例子讲一下现实中是如何进行DST的，实现的模型是十分经典的Neural Belief Tracker。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">之前我们提到先进行NLU再进行DST和DPL，而Neural Belief Tracker则是把NLU和DST合并在一起，既然NLU分析得到的slot很可能不准确，那就直接不单独分析单句话的语义，而是连着两句话进行分析（假设当前对话语义只和上一轮对话紧密相连，马尔可夫假设），所以Neural Belief Tracker分析的对象（输入）是上一轮的输入和当前的输入，同时还有所有候选的slot-value pairs（比如food：Japanese、food：Chinese……），输出就是slot-value pairs，所以也可以说，Neural Belief Tracker就是根据两轮对话的情况，从所有可能的slot-value pairs中找出符合当前真实语义的slot-value pairs。</div>
                <div class="p-service-index-map__image c-fade-in-up js-scroll-item is-shown">
                    <picture>
                        <source media="(max-width: 568px)" srcset="image/1.png"><img src="image/1.png" alt="ポジショニングマップ">
                    </picture>
                </div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">这是整个模型的结构图，从最上层开始看起，分别是system output、user utterance和candidate pair，user utterance就是当前的模型输入句子，candidate pair就是所有可能的slot-value，重点在于system output，也就是上一轮系统的输出，这是比较有意思的一个地方，在任务导向型对话系统中，系统的output可以分为两种，一种是system request，主要为了询问用户关于某些slot的value，比如问"想要买什么时候的机票"，另一种就是system confirm，是为了确定一些特定的slot-value是否正确，比如问用户"你购买的是三号从上海飞北京的机票，信息正确吗？"，对于system request，system output直接用特定的slot的embedding向量tq表示，对于system confirm，output是特定的slot-value的embedding向量（ts，tv）表示，注意！注意！注意！这里的括号是表示这是一个二元组，不是一个数组，也没有拼接在一起的意思。对于system output，说到底都是用slot或者slot-value的embedding向量表示，而不是用系统最终生成的语句表示，当然这也有道理，毕竟用系统生成的语句表示，说到底还是需要通过NLU转化为slot-value，还不如一开始就是用上一轮生成的slot。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">所以来到第二层，就可以知道，context represantation就是指（tq，ts，tv）这些slot或者slot-value的embedding向量，因为要么是slot要么是slot-value，所以当其中一个不存在时就用零向量表示。对于candidate represantation，也是slot-value的embedding向量（cs，cv）。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">然后我们来看看utterance representation，注意在把句子的单词替换成词向量之后，还需要进行所谓的representation learning，目的是用单一一个向量r表示整个句子的语义。论文中提到了NBT-DNN和NBT-CNN两种方法，首先来看NBT-DNN：</div>
                <div class="p-service-index-map__image c-fade-in-up js-scroll-item is-shown">
                    <picture>
                        <source media="(max-width: 568px)" srcset="image/2.png"><img src="image/2.png" alt="ポジショニングマップ">
                    </picture>
                </div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">图中的r1通过把整个句子的一个一个单词加起来计算的，而r2则是先把每两个相邻的单词拼接在一起，再把拼接后的向量加起来，类似的，r3就是把相邻的三个向量拼接后，再相加，举个例子，"How are you"，r1就是把"How"、"are"、"you"的词向量加起来，r2就是把"How are"、"are you"的词向量加起来，r3就是"how are you"这个词向量，当然实际处理过程中我觉得会有一个padding操作，使得处理后的向量数量相等，不然r2比r1少了一个向量，r3又少了一个，这样后续处理就比较麻烦了。用公式表示就是：</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$v_i^n = u_i \bigoplus ... \bigoplus u_{i+n-1}$$</section></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">上式表示句子第i位置n个向量的拼接。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$r_n = \sum_{i=1}^{k_u -n+1} v_i^n$$</section></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">上式就是把拼接后的向量进行加法，从而得到r1、r2、r3，然后再经过线性变换和非线性变换(sigmoid函数)得到r'：</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$r_n' = \sigma (W_n^s r_n + b_n^s)$$</section></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">最后再把三个变量加起来得到最终的向量r：</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$r =r_1' +  r_2' + r_3'$$</section></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">简单来说，上面就是对句子中的1-gram、2-gram、3-gram分别利用神经网络提取特征，再相加得到整个句子的特征向量。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">明白了NBT-DNN的思想，NBT-CNN就不难理解了，其实只是换成CNN提取特征而已：</div>
                <div class="p-service-index-map__image c-fade-in-up js-scroll-item is-shown">
                    <picture>
                        <source media="(max-width: 568px)" srcset="image/3.png"><img src="image/3.png" alt="ポジショニングマップ">
                    </picture>
                </div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">假设词向量尺寸为300，那么就用300*1、300*2、300*3三种不同尺寸的卷积核进行卷积运算得到R1、R2、R3，然后再用激活函数和最大池化处理一下：</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$r_n' = maxpool(ReLU(R_n + b_n^s))$$</section></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">本质上来说还是对于不同的n-gram采用CNN提取一下特征，最后再加起来得到最终的向量r。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">接下来继续看第三层，先看semantic decoding，主要是分析用户的输入有没有匹配到相应的candidate pairs，当然这是在没有考虑system output的情况下，之前我们已经得到了utterance representation r和candidate representation （cs，cv），如果slot或者value有多个单词就加起来，确保cs和cv是单个向量，然后模型会通过单层神经网络学习出单个语义向量表示出cs和cv：</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$c = \sigma (W_c^s (c_s + c_v) + b_c^s)$$</section></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">同时上述的线性变换也确保了最终得到的c和r的尺寸是一致的，以便继续进行element-wise的乘法计算相似度：</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$d = r \bigotimes c$$</section></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">再来看看context modelling，这个有点复杂，先来看看公式：</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$m_r = (c_s \cdot t_q)r$$</section></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$m_r = (c_s \cdot t_s)(c_v \cdot t_v)r$$</section></div>

                <div class="p-lower-kv__outline p-lower-kv__outline--col2">还记得一开始说过，system output可能是slot也可能是slot-value pairs，所以这里分两种情况又两种公式，首先我们要进行的是system output和当前的candidate pair的相似度计算，这里相当于一个门机制，我是这样理解的，假设上一轮system output的内容是food（没有value），tq=（1，0，0），现在的candidate pair是food：Indian，词向量可能是cs=（0.9,0.1,0.2），这样点积的结果是（0.9，0，0），还有一种情况，candidate可能是sports：basketball，向量cs=（0，0，1），这时候点积结果就是（0，0，0），所以，通过system output和candidate pair的点积运算，得到的向量其实是可以反映出两者的关联的。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">然后再用得到的相似度向量乘utterance r，按照论文的说法，这样的目的是只传递和system output、candidate pair都相关的信息，比如说system output和candidate pair都提到food，就抽取出utterance中的food的信息作为context modelling的结果。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">以上的方法，论文还提到一个很重要的作用，在system out是confirm的情况下，比如"would you like indian food？"这时候用户的回答可能只是一个"yes"，并不包含任何的slot-value，但是实际上这个yes的意思就是确认了food：indian这个slot-value pair的正确性，为了能发掘出这一层意思，模型在分析的过程中就必须考虑到utterance、candidate pair和system output之间的interaction，而context modelling的作用就是提供这三者的interaction（三个向量相乘）。其实个人觉得这种说法有点玄乎，但是既然出效果了就当他可行吧。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">最后，终于到了binary decision making，通过神经网络基于context modelling和semantic modelling的结果进行简单的二分类，从而分析出user utterance和当前的candidate pair到底有没有联系，如果有就说明用户的输入可以反映出food：persian这个信息，没有就继续分析下一个candidate pair，一直把所有candidate pairs都分析一遍，从而把user utterance中所有有关的slot-value pair都找出来。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">再总结一下整个模型的流程，首先，模型的目的就是基于上一轮系统的输出和当前系统的输入，分析输入和候选的slot-value pair有没有关系，怎么看有没有关系，自然就是对候选的pair逐个进行分析，逐个进行二分类，在分析的过程中，首先需要进行representation learning，把output、utterance和candidate pair都转化为向量，然后一方面分析utterance和candidate pair的关系，一方面综合分析system output、utterance和candidate pair之间的关系，最后再把分析出来的特征向量传入神经网络进行二分类，判断utterance有没有包含当前的candidate pair。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">对于模型的评价，整个模型可以看成三层，第一层是embedding层，第二层是特征提取层，第三层是分类层，主要还是在于特征提取层，是否有必要分为context modelling和semantic decoding两个部分，引入门控结构是否真的有作用，这样的结构会比单纯的多层神经网络更能有效地提取特征吗，当然这些疑问需要进一步的实验才能验证，不论怎样，Neural Belief Tracker是一个很棒的模型，提出了一个很好地利用神经网络综合分析两轮对话和slot-value的关系的思路。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
               

            </div>

        <!-- End to define the main content.-->
      </div>


    </div>
    <script src="../../css/main/main.min.js" async=""></script>

    <script type="text/javascript" defer=""
            src="../../css/menu/autoptimize_73b1aaeb49de3f7372d04614ffa9ecd3.js"></script>

</body></html>