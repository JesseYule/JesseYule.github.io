<!DOCTYPE html>
<!-- saved from url=(0029)https://carrac.co.jp/service/ -->
<html lang="ja"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Jesse Yule's Blog</title>
    <meta name="viewport" content="width=device-width">

    <style>.l-page { visibility: hidden; }</style>
    <link rel="stylesheet" as="style" href="../../css/main/main.min.css">
    <link rel="apple-touch-icon" sizes="180x180" href="https://carrac.co.jp/img/common/app_icon.png">

    <link rel="stylesheet" href="../../css/menu/common.css" media="all">
    <link rel="stylesheet" href="../../css/menu/home.css" media="all">
    <script type="text/javascript" async="" src="../../css/menu/analytics.js"></script>
    <script async="" src="../../css/menu/js"></script>


    <meta name="theme-color" content="#ffffff">
    <!-------------------------matjax------------------------------>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
    <!---------------------------------------------------------------->
    <script type="text/javascript" async="" src="../../css/main/analytics.js"></script><script async="" src="../../css/main/gtm.js"></script><script>
      (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
      new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
      j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
      })(window,document,'script','dataLayer','GTM-KHDRBVP');
    </script>
    <!-- End Google Tag Manager -->
  </head>
  <body style="font-family: 等线, 等线 Light,'微软雅黑 Light',Helvetica Neue, Helvetica, Arial, PingFang SC; font-weight: lighter ;word-break: break-all ;background-color: #323638 ">
    <!-- Google Tag Manager (noscript) -->
    <noscript>
      &lt;iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KHDRBVP"
      height="0" width="0" style="display:none;visibility:hidden"&gt;
      &lt;/iframe&gt;
    </noscript>
    <!-- End Google Tag Manager (noscript) -->
    
    <div class="l-page" data-page-id="service">
      <!-- Start to define the global header.-->
      <div class="l-gh"></div>
      <!-- End to define the global header.-->




      <div class="l-contents">
        <!-- Start to define the main content.-->

          <header class="st-hdr" id="js-hdr">
              <div class="hdr-bar m-row m-row--jc--spacebetween m-row--ai--center">

              </div>

          </header>

          <button class="trigger" id="js-trigger"><span></span><span></span><span></span></button>



          <nav class="overlay-navigation" style="color: #eeeeee">
              <div class="overlay-navigation__inner m-row">
                  <div class="overlay-navigation__block">
                      <ul class="sitemap m-row m-row--fw--wrap">

                              <li class="sitemap__unit"><a href="../../index.html">Home</a></li>

                          <li class="sitemap__unit"><a href="../../about/about.html">About</a></li>

                          <li class="sitemap__unit"><a href="../../programming/java1.html">Java</a></li>



                          <li class="sitemap__unit"><a href="../../math/all1.html">Mathematics</a></li>

                          <li class="sitemap__unit"><a href="../../naturallanguage/all1.html">Natural Language</a></li>

                          <li class="sitemap__unit"><a href="../../machinelearning/ml1.html">Machine Learning</a></li>

<li class="sitemap__unit"><a href="../../articles/all1.html">Others</a></li>

                      </ul>

                  </div>
                  <div class="sns"><h2 class="overlay-navigation__siteID"><img src="../../css/menu/img_siteID-m.svg"
                                                                               alt=""></h2></div>
              </div>
          </nav>



          <div class="p-lower">
          <div class="c-red-line c-slide-in u-animdel-100"></div>
          <h2 class="p-lower__title-en c-slide-in u-animdel-100">DST与Neural Belief Tracker</h2>

		  
		   <div class="p-lower-kv">
            <div class="p-lower-kv__text">
              <div class="p-lower-kv__subtitle">  </div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">之前介绍了自然语言理解、对话管理，其中对话管理包括DST和DPL，简单再说一遍，NLU是为了分析单一输入的语义，通过intent和slot表示语义，而DST是为了结合当前输入、上一时刻的输入和上一时刻系统的action分析出综合语义state（一般都是指slot-value），一般是指对NLU得到的slot进行更新，而DPL则是基于得到的state分析action。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">这里主要结合具体的模型讲一下现实中是如何进行DST的，这个模型是十分经典的Neural Belief Tracker，模型的结构原理真的很厉害，真的很值得细细品味。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">之前我们提到先进行NLU再进行DST和DPL，而Neural Belief Tracker则提出把NLU和DST合并在一起，既然NLU分析得到的slot很可能不准确，那就直接不单独分析单句话的语义，而是连着两句话进行分析（假设当前对话语义只和上一轮对话紧密相连，马尔可夫假设），所以Neural Belief Tracker分析的对象（输入）是上一轮的系统输出和当前的输入，同时还有所有候选的slot-value pairs中的某一个，输出就是一个二分类结果"有关联"或者"没有关联"，通过遍历所有slot-value pairs，从而把所有和当前输入有关联的slot-value都找出来。</div>
                <div class="p-service-index-map__image c-fade-in-up js-scroll-item is-shown">
                    <picture>
                        <source media="(max-width: 568px)" srcset="image/1.png"><img src="image/1.png" alt="ポジショニングマップ">
                    </picture>
                </div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">这是整个模型的结构图，从最上层开始看起，分别是system output、user utterance和candidate pair，user utterance就是当前的模型输入句子，candidate pair就是所有可能的slot-value，重点在于system output，也就是上一轮系统的输出，这是比较有意思的一个地方，在任务导向型对话系统中，系统的output可以分为两种，一种是system request，主要为了询问用户关于某些slot的value，比如问"想要买什么时候的机票"，另一种就是system confirm，是为了确定一些特定的slot-value是否正确，比如问用户"你购买的是三号从上海飞北京的机票，信息正确吗？"，对于system request，system output直接用特定的slot的embedding向量tq表示，对于system confirm，output是特定的slot-value的embedding向量（ts，tv）表示，注意！注意！注意！这里的括号是表示这是一个二元组，不是一个数组，也没有拼接在一起的意思。对于system output，说到底都是用slot或者slot-value的embedding向量表示，而不是用系统上一轮生成的语句表示，当然这也有道理，毕竟用系统生成的语句表示，说到底还是需要通过NLU转化为slot-value，还不如一开始就是用上一轮最终生成的slot-value。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">所以来到第二层，就可以知道，context represantation就是指（tq，ts，tv）这些slot或者slot-value的embedding向量，因为要么是slot要么是slot-value，所以当其中一个不存在时就用零向量表示。对于candidate represantation，也是slot-value的embedding向量（cs，cv）。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">然后我们来看看utterance representation，注意在把句子的单词替换成词向量之后，还需要进行所谓的representation learning，目的是用单一一个向量r表示整个句子的语义。论文中提到了NBT-DNN和NBT-CNN两种方法，首先来看NBT-DNN：</div>
                <div class="p-service-index-map__image c-fade-in-up js-scroll-item is-shown">
                    <picture>
                        <source media="(max-width: 568px)" srcset="image/2.png"><img src="image/2.png" alt="ポジショニングマップ">
                    </picture>
                </div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">图中的r1通过把整个句子的一个一个单词加起来计算的，而r2则是先把每两个相邻的单词拼接在一起，再把拼接后的向量加起来，类似的，r3就是把相邻的三个向量拼接后，再相加，举个例子，"How are you"，r1就是把"How"、"are"、"you"的词向量加起来，r2就是把"How are"、"are you"的词向量加起来，r3就是"how are you"这个词向量，当然实际处理过程中我觉得会有一个padding操作，使得处理后的向量数量相等，不然r2比r1少了一个向量，r3又少了一个，这样后续处理就比较麻烦了。用公式表示就是：</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$v_i^n = u_i \bigoplus ... \bigoplus u_{i+n-1}$$</section></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">上式表示句子第i位置n个向量的拼接。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$r_n = \sum_{i=1}^{k_u -n+1} v_i^n$$</section></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">上式就是把拼接后的向量进行加法，从而得到r1、r2、r3，然后再经过线性变换和非线性变换(sigmoid函数)得到r'：</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$r_n' = \sigma (W_n^s r_n + b_n^s)$$</section></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">最后再把三个变量加起来得到最终的向量r：</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$r =r_1' +  r_2' + r_3'$$</section></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">简单来说，上面就是对句子中的1-gram、2-gram、3-gram分别利用神经网络提取特征，再相加得到整个句子的特征向量。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">明白了NBT-DNN的思想，NBT-CNN就不难理解了，其实只是换成CNN提取特征而已：</div>
                <div class="p-service-index-map__image c-fade-in-up js-scroll-item is-shown">
                    <picture>
                        <source media="(max-width: 568px)" srcset="image/3.png"><img src="image/3.png" alt="ポジショニングマップ">
                    </picture>
                </div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">假设词向量尺寸为300，那么就用300*1、300*2、300*3三种不同尺寸的卷积核进行卷积运算得到R1、R2、R3，然后再用激活函数和最大池化处理一下：</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$r_n' = maxpool(ReLU(R_n + b_n^s))$$</section></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">本质上来说还是对于不同的n-gram采用CNN提取一下特征，最后再加起来得到最终的向量r。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">接下来继续看第三层，先看semantic decoding，主要是分析用户的输入有没有匹配到相应的candidate pairs，当然这是在没有考虑system output的情况下，之前我们已经得到了utterance representation r和candidate representation （cs，cv），如果slot或者value有多个单词就加起来，确保cs和cv是单个向量，然后模型会通过单层神经网络学习出单个语义向量表示出cs和cv：</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$c = \sigma (W_c^s (c_s + c_v) + b_c^s)$$</section></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">同时上述的线性变换也确保了最终得到的c和r的尺寸是一致的，以便继续进行element-wise的乘法计算相似度：</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$d = r \bigotimes c$$</section></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">再来看看context modelling，这个有点复杂，先来看看公式：</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$m_r = (c_s \cdot t_q)r$$</section></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><section style="text-align: center; margin:0 auto">$$m_r = (c_s \cdot t_s)(c_v \cdot t_v)r$$</section></div>

                <div class="p-lower-kv__outline p-lower-kv__outline--col2">还记得一开始说过，system output可能是slot也可能是slot-value pairs，所以这里分两种情况有两种公式，首先我们要进行的是system output和当前的candidate pair的相似度计算，这里相当于一个门机制，我是这样理解的，假设上一轮system output的内容是food（没有value），tq=（1，0，0），现在的candidate pair是food：Indian，词向量可能是cs=（0.9,0.1,0.2），这样点积的结果是0.9+0+0=0.9，还有一种情况，candidate可能是sports：basketball，向量cs=（0，0，1），这时候点积结果就是0+0+0=0，所以，通过system output和candidate pair的点积运算，得到的数值其实是可以反映出两者的关联的。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">然后再用得到的相似度乘以utterance r，按照论文的说法，目的是只传递和system output、candidate pair都相关的信息，比如说system output和candidate pair都提到food，相似度就比较高，utterance就可以比较完整地传递过去，如果system output和当前的candidate pair不相关，最终计得的context modelling向量甚至可能接近0。关于这点，也比较好理解，假如当前的candidate pair是food：persian，而上一轮的output是sport：basketball，那么就完全不相关了，既然上一轮系统在谈论运动和篮球的话题，那么这一轮用户的回答应该也是和这个话题有关的，换句话说当前的输入很大概率和candidate pairs无关，而这种无关性就可以通过接近0的context modelling向量反映。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">以上的方法，论文还提到一个很重要的作用，在system output是confirm的情况下，比如"would you like indian food？"这时候用户的回答可能只是一个"yes"，并不包含任何的slot-value，但是实际上这个yes的意思就是确认了food：indian这个slot-value pair的正确性，我们当然可以知道yes包含了这层意思，可是模型怎么学习出这层意思呢，这就是context modelling这个结构最巧妙的地方，注意！注意！注意！当system output和candidate pair高度相关时，user utterance能够完整地传递给context modelling，也就是"yes"的语义向量能比较完整地传给context modelling模块，而当模型遇到多次"yes"，都发现system output和candidate pair都高度相关时，模型就能领悟到，只要下次也接收到这个"yes"，就意味着它包含了上一轮system output的slot-value，所以说，这个context modelling，真的是整个模型最叹为观止的地方。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">最后，终于到了binary decision making，通过神经网络基于context modelling和semantic modelling的结果进行二分类，从而分析出user utterance和当前的candidate pair到底有没有联系，如果有就说明用户的输入可以反映出candidate pair的信息，没有就继续分析下一个candidate pair，一直把所有candidate pairs都分析一遍，从而把user utterance中所有有关的slot-value pair都找出来。</div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2"><br></div>
                <div class="p-lower-kv__outline p-lower-kv__outline--col2">再总结一下整个模型的流程，首先，模型的目的是基于上一轮系统的输出和当前系统的输入，分析输入和候选的slot-value pair有没有关系，怎么看有没有关系，自然就是对候选的pair逐个进行分析，逐个进行二分类，在分析的过程中，首先需要进行representation learning，把output、utterance和candidate pair都转化为向量，然后一方面分析utterance和candidate pair的关系，一方面综合分析system output、utterance和candidate pair之间的关系，最后再把分析出来的特征传入神经网络进行二分类，判断utterance有没有包含当前的candidate pair信息。</div>

               

            </div>

        <!-- End to define the main content.-->
      </div>


    </div>
    <script src="../../css/main/main.min.js" async=""></script>

    <script type="text/javascript" defer=""
            src="../../css/menu/autoptimize_73b1aaeb49de3f7372d04614ffa9ecd3.js"></script>

</body></html>